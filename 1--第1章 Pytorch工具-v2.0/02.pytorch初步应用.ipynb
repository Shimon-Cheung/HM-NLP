{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Pytorch构建一个神经网络\n",
    "### 首先定义一个Pytorch实现的神经网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b093a69a963565a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 导入若干工具包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# 定义一个简单的网络类\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 定义第一层卷积神经网络, 输入通道维度=1, 输出通道维度=6, 卷积核大小3*3\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)\n",
    "        # 定义第二层卷积神经网络, 输入通道维度=6, 输出通道维度=16, 卷积核大小3*3\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        # 定义三层全连接网络\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 在(2, 2)的池化窗口下执行最大池化操作\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        # 计算size, 除了第0个维度上的batch_size\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.191647Z",
     "start_time": "2023-12-12T02:26:08.408283Z"
    }
   },
   "id": "df8c19f5a0695c82"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型中所有的可训练参数, 可以通过net.parameters()来获得"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fff51c6133cbead9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.192766Z",
     "start_time": "2023-12-12T02:26:09.190306Z"
    }
   },
   "id": "f552c47810af2e3d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0035, -0.0401,  0.0804,  0.0795,  0.1614,  0.0771, -0.0114, -0.0514,\n",
      "         -0.0514,  0.0649]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.209466Z",
     "start_time": "2023-12-12T02:26:09.193131Z"
    }
   },
   "id": "97d07140d438d13f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 有了输出张量后, 就可以执行梯度归零和反向传播的操作了"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f85c403841109e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.241896Z",
     "start_time": "2023-12-12T02:26:09.209499Z"
    }
   },
   "id": "2078926541680ded"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 损失函数\n",
    "- 损失函数的输入是一个输入的pair: (output, target), 然后计算出一个数值来评估output和target之间的差距大小.\n",
    "- 在torch.nn中有若干不同的损失函数可供使用, 比如nn.MSELoss就是通过计算均方差损失来评估输入和目标值之间的差距."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78618c8b3fc147c0"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0923, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)\n",
    "\n",
    "# 改变target的形状为二维张量, 为了和output匹配\n",
    "target = target.view(1, -1)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.242266Z",
     "start_time": "2023-12-12T02:26:09.235096Z"
    }
   },
   "id": "269728ec1070d3c0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x103e547f0>\n",
      "<AddmmBackward0 object at 0x103e547c0>\n",
      "<AccumulateGrad object at 0x103e547f0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.242876Z",
     "start_time": "2023-12-12T02:26:09.239474Z"
    }
   },
   "id": "59467ae6b5e016dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 反向传播(backpropagation)\n",
    "- 在Pytorch中执行反向传播非常简便, 全部的操作就是loss.backward().\n",
    "- 在执行反向传播之前, 要先将梯度清零, 否则梯度会在不同的批次数据之间被累加."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a0a4dbf572ed2be"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0020,  0.0019,  0.0138, -0.0046,  0.0002, -0.0043])\n"
     ]
    }
   ],
   "source": [
    "# Pytorch中执行梯度清零的代码\n",
    "net.zero_grad()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "# Pytorch中执行反向传播的代码\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.252009Z",
     "start_time": "2023-12-12T02:26:09.243327Z"
    }
   },
   "id": "cd0db48f43acb7d8"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 首先导入优化器的包, optim中包含若干常用的优化算法, 比如SGD, Adam等\n",
    "import torch.optim as optim\n",
    "\n",
    "# 通过optim创建优化器对象\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# 将优化器执行梯度清零的操作\n",
    "optimizer.zero_grad()\n",
    "\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "# 对损失值执行反向传播的操作\n",
    "loss.backward()\n",
    "# 参数的更新通过一行标准代码来执行\n",
    "optimizer.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:09.375348Z",
     "start_time": "2023-12-12T02:26:09.248165Z"
    }
   },
   "id": "b837d4e7a879ca15"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 使用Pytorch构建一个分类器\n",
    "### 训练分类器的步骤\n",
    "#### 1: 使用torchvision下载CIFAR10数据集\n",
    "#### 2: 定义卷积神经网络\n",
    "#### 3: 定义损失函数\n",
    "#### 4: 在训练集上训练模型\n",
    "#### 5: 在测试集上测试模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a0a2305a941e3112"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1: 使用torchvision下载CIFAR10数据集"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da81771c809bf1c5"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 预处理管道，一般都用来进行tensor和归一化处理。\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # tensor化处理\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # 归一化处理\n",
    "    ]\n",
    ")\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=4, shuffle=False, num_workers=2\n",
    ")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:10.910572Z",
     "start_time": "2023-12-12T02:26:09.376521Z"
    }
   },
   "id": "7765050d21e9dcb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2: 定义卷积神经网络"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "786bd161497c39ea"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import functional\n",
    "\n",
    "\n",
    "class NetClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(functional.relu(self.conv1(x)))\n",
    "        x = self.pool(functional.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = functional.relu(self.fc1(x))\n",
    "        x = functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net_class = NetClass()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:10.917188Z",
     "start_time": "2023-12-12T02:26:10.914056Z"
    }
   },
   "id": "a353f416aa22095d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3: 定义损失函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "447ad0d5e55ec5d4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 采用交叉熵损失函数和随机梯度下降优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net_class.parameters(), lr=0.001, momentum=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:26:10.920162Z",
     "start_time": "2023-12-12T02:26:10.917237Z"
    }
   },
   "id": "69eaf9629e5e99bb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4: 在训练集上训练模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "822c69999797eaac"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.292\n",
      "[1,  4000] loss: 1.962\n",
      "[1,  6000] loss: 1.737\n",
      "[1,  8000] loss: 1.617\n",
      "[1, 10000] loss: 1.548\n",
      "[1, 12000] loss: 1.473\n",
      "[2,  2000] loss: 1.406\n",
      "[2,  4000] loss: 1.382\n",
      "[2,  6000] loss: 1.357\n",
      "[2,  8000] loss: 1.333\n",
      "[2, 10000] loss: 1.312\n",
      "[2, 12000] loss: 1.296\n",
      "[3,  2000] loss: 1.226\n",
      "[3,  4000] loss: 1.199\n",
      "[3,  6000] loss: 1.221\n",
      "[3,  8000] loss: 1.192\n",
      "[3, 10000] loss: 1.174\n",
      "[3, 12000] loss: 1.192\n",
      "[4,  2000] loss: 1.102\n",
      "[4,  4000] loss: 1.112\n",
      "[4,  6000] loss: 1.115\n",
      "[4,  8000] loss: 1.102\n",
      "[4, 10000] loss: 1.095\n",
      "[4, 12000] loss: 1.117\n",
      "[5,  2000] loss: 1.030\n",
      "[5,  4000] loss: 1.034\n",
      "[5,  6000] loss: 1.026\n",
      "[5,  8000] loss: 1.064\n",
      "[5, 10000] loss: 1.051\n",
      "[5, 12000] loss: 1.040\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # data中包含输入图像张量inputs, 标签张量labels\n",
    "        inputs, labels = data\n",
    "\n",
    "        # 首先将优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 输入图像张量进网络, 得到输出张量outputs\n",
    "        outputs = net_class(inputs)\n",
    "\n",
    "        # 利用网络的输出outputs和标签labels计算损失值\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播+参数更新, 是标准代码的标准流程\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 打印轮次和损失值\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % 2000 == 0:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:28:13.778666Z",
     "start_time": "2023-12-12T02:26:10.920430Z"
    }
   },
   "id": "6ccb16e6e8f5034c"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 首先设定模型的保存路径\n",
    "PATH = './cifar_net.pth'\n",
    "# 保存模型的状态字典\n",
    "torch.save(net.state_dict(), PATH)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:33:56.961383Z",
     "start_time": "2023-12-12T02:33:56.943620Z"
    }
   },
   "id": "508b66cd189786bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5: 在测试集上测试模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6457e005cdf9647"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 16\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# 从数据迭代器中读取一张图片\u001B[39;00m\n\u001B[1;32m     15\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(trainloader)\n\u001B[0;32m---> 16\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[43mdataiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnext\u001B[49m()\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# 展示图片\u001B[39;00m\n\u001B[1;32m     19\u001B[0m imshow(torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mmake_grid(images))\n",
      "\u001B[0;31mAttributeError\u001B[0m: '_MultiProcessingDataLoaderIter' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "# 导入画图包和numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 构建展示图片的函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 从数据迭代器中读取一张图片\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印标签label\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:36:36.120254Z",
     "start_time": "2023-12-12T02:36:29.043842Z"
    }
   },
   "id": "7f79d4786c2c5d69"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for NetClass:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([6, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([6, 3, 5, 5]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([16, 6, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 6, 5, 5]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([120, 576]) from checkpoint, the shape in current model is torch.Size([120, 400]).",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m net_test \u001B[38;5;241m=\u001B[39m NetClass()\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# 加载训练阶段保存好的模型的状态字典\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[43mnet_test\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_state_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mPATH\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m dataiter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28miter\u001B[39m(testloader)\n\u001B[1;32m      6\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m dataiter\u001B[38;5;241m.\u001B[39mnext()\n",
      "File \u001B[0;32m~/Desktop/HM-NLP/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:2152\u001B[0m, in \u001B[0;36mModule.load_state_dict\u001B[0;34m(self, state_dict, strict, assign)\u001B[0m\n\u001B[1;32m   2147\u001B[0m         error_msgs\u001B[38;5;241m.\u001B[39minsert(\n\u001B[1;32m   2148\u001B[0m             \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMissing key(s) in state_dict: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2149\u001B[0m                 \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m missing_keys)))\n\u001B[1;32m   2151\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(error_msgs) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m-> 2152\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mError(s) in loading state_dict for \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m   2153\u001B[0m                        \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(error_msgs)))\n\u001B[1;32m   2154\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Error(s) in loading state_dict for NetClass:\n\tsize mismatch for conv1.weight: copying a param with shape torch.Size([6, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([6, 3, 5, 5]).\n\tsize mismatch for conv2.weight: copying a param with shape torch.Size([16, 6, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 6, 5, 5]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([120, 576]) from checkpoint, the shape in current model is torch.Size([120, 400])."
     ]
    }
   ],
   "source": [
    "# 首先实例化模型的类对象\n",
    "net_test = NetClass()\n",
    "# 加载训练阶段保存好的模型的状态字典\n",
    "net_test.load_state_dict(torch.load(PATH))\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "# 打印原始图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印真实的标签\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "# 利用模型对图片进行预测\n",
    "outputs = net_test(images)\n",
    "\n",
    "# 共有10个类别, 采用模型计算出的概率最大的作为预测的类别\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# 打印预测标签的结果\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T02:37:36.743770Z",
     "start_time": "2023-12-12T02:37:36.694126Z"
    }
   },
   "id": "61714d4fd595f3b6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
