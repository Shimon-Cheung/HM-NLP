{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 什么是文本张量表示\n",
    "将一段文本使用张量进行表示，其中一般将词汇为表示成向量，称作词向量，再由各个词向量按顺序组成矩阵形成文本表示."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 举个例子\n",
    "# [\"人生\", \"该\", \"如何\", \"起头\"]\n",
    "# 每个词对应矩阵中的一个向量\n",
    "# [[1.32, 4,32, 0,32, 5.2],\n",
    "#  [3.1, 5.43, 0.34, 3.2],\n",
    "#  [3.21, 5.32, 2, 4.32],\n",
    "#  [2.54, 7.32, 5.12, 9.54]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 文本张量表示的作用\n",
    "将文本表示成张量（矩阵）形式，能够使语言文本可以作为计算机处理程序的输入，进行接下来一系列的解析工作."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 文本张量表示的方法:\n",
    "- one-hot编码\n",
    "- Word2vec\n",
    "- Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 什么是one-hot词向量表示\n",
    "又称独热编码，将每个词表示成具有n个元素的向量，这个词向量中只有一个元素是1，其他元素都是0，不同词汇元素为0的位置不同，其中n的大小是整个语料中不同词汇的总数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "[\"改变\", \"要\", \"如何\", \"起手\"]`\n",
    "==>\n",
    "\n",
    "[[1, 0, 0, 0],\n",
    " [0, 1, 0, 0],\n",
    " [0, 0, 1, 0],\n",
    " [0, 0, 0, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### onehot编码实现:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李宗盛 的one-hot编码为: [1, 0, 0, 0, 0, 0]\n",
      "王力宏 的one-hot编码为: [0, 1, 0, 0, 0, 0]\n",
      "吴亦凡 的one-hot编码为: [0, 0, 1, 0, 0, 0]\n",
      "周杰伦 的one-hot编码为: [0, 0, 0, 1, 0, 0]\n",
      "陈奕迅 的one-hot编码为: [0, 0, 0, 0, 1, 0]\n",
      "鹿晗 的one-hot编码为: [0, 0, 0, 0, 0, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": "['./Tokenizer']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入用于对象保存与加载的joblib\n",
    "import joblib\n",
    "# 导入keras中的词汇映射器Tokenizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 假定vocab为语料集所有不同词汇集合\n",
    "vocab = {\"周杰伦\", \"陈奕迅\", \"王力宏\", \"李宗盛\", \"鹿晗\", \"吴亦凡\"}\n",
    "# 实例化一个词汇映射器对象\n",
    "t = Tokenizer(num_words=None, char_level=False)\n",
    "# 使用映射器拟合现有文本数据\n",
    "t.fit_on_texts(vocab)\n",
    "\n",
    "for token in vocab:\n",
    "    zero_list = [0] * len(vocab)\n",
    "    # 使用映射器转化现有文本数据, 每个词汇对应从1开始的自然数\n",
    "    # 返回样式如: [[2]], 取出其中的数字需要使用[0][0]\n",
    "    token_index = t.texts_to_sequences([token])[0][0] - 1\n",
    "    zero_list[token_index] = 1\n",
    "    print(token, \"的one-hot编码为:\", zero_list)\n",
    "\n",
    "# 使用joblib工具保存映射器, 以便之后使用\n",
    "tokenizer_path = \"./Tokenizer\"\n",
    "joblib.dump(t, tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "李宗盛 的one-hot编码为: [1, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# 导入用于对象保存与加载的joblib\n",
    "# from sklearn.externals import joblib\n",
    "# 加载之前保存的Tokenizer, 实例化一个t对象\n",
    "t = joblib.load(tokenizer_path)\n",
    "\n",
    "# 编码token为\"李宗盛\"\n",
    "token = \"李宗盛\"\n",
    "# 使用t获得token_index\n",
    "token_index = t.texts_to_sequences([token])[0][0] - 1\n",
    "# 初始化一个zero_list\n",
    "zero_list = [0] * len(vocab)\n",
    "# 令zero_List的对应索引为1\n",
    "zero_list[token_index] = 1\n",
    "print(token, \"的one-hot编码为:\", zero_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### one-hot编码的优劣势：\n",
    "- 优势：操作简单，容易理解.\n",
    "- 劣势：完全割裂了词与词之间的联系，而且在大语料集下，每个向量的长度过大，占据大量内存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 什么是word2vec\n",
    "是一种流行的将词汇表示成向量的无监督训练方法, 该过程将构建神经网络模型, 将网络参数作为词汇的向量表示, 它包含CBOW和skipgram两种训练模式.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6aa5a1d016f25af40e674d7c60aac6831c365efeab2cb1d8bc3f02eedcf7a95c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
